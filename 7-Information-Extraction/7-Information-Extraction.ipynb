{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Week 7 - Information Extraction\n",
    "\n",
    "\n",
    "This week, we move from arbitrary textual classification to the use of computation and linguistic models to parse precise claims from documents. Rather than focusing on simply the *ideas* in a corpus, here we focus on understanding and extracting its precise *claims*. This process involves a sequential pipeline of classifying and structuring tokens from text, each of which generates potentially useful data for the content analyst. Steps in this process, which we examine in this notebook, include: 1) tagging words by their part of speech (POS) to reveal the linguistic role they play in the sentence (e.g., Verb, Noun, Adjective, etc.); 2) tagging words as named entities (NER) such as places or organizations; 3) structuring or \"parsing\" sentences into nested phrases that are local to, describe or depend on one another; and 4) extracting informational claims from those phrases, like the Subject-Verb-Object (SVO) triples we extract here. While much of this can be done directly in the python package NLTK that we introduced in week 2, here we use NLTK bindings to the Stanford NLP group's open software, written in Java. Try typing a sentence into the online version [here](http://nlp.stanford.edu:8080/corenlp/) to get a sense of its potential. It is superior in performance to NLTK's implementations, but takes time to run, and so for these exercises we will parse and extract information for a very small text corpus. Of course, for final projects that draw on these tools, we encourage you to install the software on your own machines or shared servers at the university (RCC, SSRC) in order to perform these operations on much more text. \n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You need to run this _once_ to download everything, you will also need [Java 1.8+](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) if you are using Windows or MacOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.setupStanfordNLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to have stanford-NLP setup before importing, so we are doing the import here. IF you have stanford-NLP working, you can import at the beginning like you would with any other library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Open Information Extraction is a module packaged within the Stanford Core NLP package, but it is not yet supported by `nltk`. As a result, we have defining our own `lucem_illud` function that runs the Stanford Core NLP java code right here. For other projects, it is often useful to use Java or other programs (in C, C++) within a python workflow, and this is an example. `stanford.openIE()` takes in a string or list of strings and then produces as output all the subject, verb, object (SVO) triples Stanford Corenlp can find, as a DataFrame. You can do this through links to the Stanford Core NLP project that we provide here, or play with their interface directly (in the penultimate cell of this notebook), which produces data in \"pretty graphics\" like this example parsing of the first sentence in the \"Shooting of Trayvon Martin\" Wikipedia article:\n",
    "\n",
    "![Output 1](../data/stanford_core1.png)\n",
    "![Output 2](../data/stanford_core2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, we will illustrate these tools on some *very* short examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the elephant in my pajamas.\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.\n",
      "Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [nltk.word_tokenize(t) for t in text]\n",
    "print('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part-of-Speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In POS tagging, we classify each word by its semantic role in a sentence. The Stanford POS tagger uses the [Penn Treebank tag set]('http://repository.upenn.edu/cgi/viewcontent.cgi?article=1603&context=cis_reports') to POS tag words from input sentences. As discussed in the second assignment, this is a relatively precise tagset, which allows more informative tags, and also more opportunities to err :-).\n",
    "\n",
    "|#. |Tag |Description |\n",
    "|---|----|------------|\n",
    "|1.\t|CC\t|Coordinating conjunction\n",
    "|2.\t|CD\t|Cardinal number\n",
    "|3.\t|DT\t|Determiner\n",
    "|4.\t|EX\t|Existential there\n",
    "|5.\t|FW\t|Foreign word\n",
    "|6.\t|IN\t|Preposition or subordinating conjunction\n",
    "|7.\t|JJ\t|Adjective\n",
    "|8.\t|JJR|\tAdjective, comparative\n",
    "|9.\t|JJS|\tAdjective, superlative\n",
    "|10.|\tLS\t|List item marker\n",
    "|11.|\tMD\t|Modal\n",
    "|12.|\tNN\t|Noun, singular or mass\n",
    "|13.|\tNNS\t|Noun, plural\n",
    "|14.|\tNNP\t|Proper noun, singular\n",
    "|15.|\tNNPS|\tProper noun, plural\n",
    "|16.|\tPDT\t|Predeterminer\n",
    "|17.|\tPOS\t|Possessive ending\n",
    "|18.|\tPRP\t|Personal pronoun\n",
    "|19.|\tPRP\\$|\tPossessive pronoun\n",
    "|20.|\tRB\t|Adverb\n",
    "|21.|\tRBR\t|Adverb, comparative\n",
    "|22.|\tRBS\t|Adverb, superlative\n",
    "|23.|\tRP\t|Particle\n",
    "|24.|\tSYM\t|Symbol\n",
    "|25.|\tTO\t|to\n",
    "|26.|\tUH\t|Interjection\n",
    "|27.|\tVB\t|Verb, base form\n",
    "|28.|\tVBD\t|Verb, past tense\n",
    "|29.|\tVBG\t|Verb, gerund or present participle\n",
    "|30.|\tVBN\t|Verb, past participle\n",
    "|31.|\tVBP\t|Verb, non-3rd person singular present\n",
    "|32.|\tVBZ\t|Verb, 3rd person singular present\n",
    "|33.|\tWDT\t|Wh-determiner\n",
    "|34.|\tWP\t|Wh-pronoun\n",
    "|35.|\tWP$\t|Possessive wh-pronoun\n",
    "|36.|\tWRB\t|Wh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pos_sents = stanford.postTagger.tag_sents(tokenized_text)\n",
    "print(pos_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This looks quite good. Now we will try POS tagging with a somewhat larger corpus. We consider a few of the top posts from the reddit data we used last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditDF = pandas.read_csv('../data/reddit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Grabbing the 10 highest scoring posts and tokenizing the sentences. Once again, notice that we aren't going to do any kind of stemming this week (although *semantic* normalization may be performed where we translate synonyms into the same focal word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditTopScores = redditDF.sort_values('score')[-10:]\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores.index = range(len(redditTopScores) - 1, -1,-1) #Reindex to make things nice in the future\n",
    "redditTopScores[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And count the number of `NN` (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What about the number of top verbs (`VB`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What about the adjectives that modify the word, \"computer\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'computer'\n",
    "NResults = set()\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluating POS tagger\n",
    "\n",
    "We can check the POS tagger by running it on a manually tagged corpus and identifying a reasonable error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "treeBank = nltk.corpus.treebank\n",
    "treeBank.tagged_sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "treeBank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stanfordTags = stanford.postTagger.tag_sents(treeBank.sents()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NumDiffs = 0\n",
    "for sentIndex in range(len(stanfordTags)):\n",
    "    for wordIndex in range(len(stanfordTags[sentIndex])):\n",
    "        if stanfordTags[sentIndex][wordIndex][1] != treeBank.tagged_sents()[sentIndex][wordIndex][1]:\n",
    "            if treeBank.tagged_sents()[sentIndex][wordIndex][1] != '-NONE-':\n",
    "                print(\"Word: {}  \\tStanford: {}\\tTreebank: {}\".format(stanfordTags[sentIndex][wordIndex][0], stanfordTags[sentIndex][wordIndex][1], treeBank.tagged_sents()[sentIndex][wordIndex][1]))\n",
    "                NumDiffs += 1\n",
    "total = sum([len(s) for s in stanfordTags])\n",
    "print(\"The Precision is {:.3f}%\".format((total-NumDiffs)/total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So we can see that the stanford POS tagger is quite good. Nevertheless, for a 20 word sentence, we only have a 66% chance ($1-.96^{20}$) of tagging (and later parsing) it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform POS tagging on a meaningful (but modest) subset of a corpus associated with your final project. Examine the list of words associated with at least three different parts of speech. Consider conditional frequencies (e.g., adjectives associated with nouns of interest or adverbs with verbs of interest). What do these distributions suggest about your corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df_total = pandas.read_pickle('../data/news_better.pkl')\n",
    "news_df = news_df_total.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['sentences'] = news_df['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['POS_sents'] = news_df['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def pos_counter(target_pos, pos_sentences):\n",
    "    targetCounts = Counter()\n",
    "    for entry in pos_sentences:\n",
    "        for sentence in entry:\n",
    "            for ent, kind in sentence:\n",
    "                if not kind.startswith(target_pos):\n",
    "                    continue\n",
    "                targetCounts.update([ent])\n",
    "    sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "    return sortedTargets\n",
    "\n",
    "def pos_collocation_counter(target_pos, pos_sentences, target_word, pos_after=False):\n",
    "    counts = Counter()\n",
    "    for entry in pos_sentences:\n",
    "        for sentence in entry:\n",
    "            for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "                if pos_after and ent2.lower()==target_word and kind1.startswith(target_pos): #(kind1,ent2.lower())==(target_pos,target_word):\n",
    "                    counts.update([ent1])\n",
    "                elif not pos_after and ent1.lower()==target_word and kind2.startswith(target_pos): #(kind2, ent1.lower())==(target_pos,target_word):\n",
    "                    counts.update([ent2])\n",
    "                else:\n",
    "                    continue\n",
    "    return sorted(counts.items(), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I´m interested in looking at combinations of verbs and modals. Let´s look at the modals in our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('will', 247),\n",
       " ('would', 130),\n",
       " ('can', 106),\n",
       " ('should', 72),\n",
       " ('could', 57),\n",
       " ('may', 31),\n",
       " ('must', 30),\n",
       " ('might', 15),\n",
       " ('wo', 6),\n",
       " (\"'ll\", 4),\n",
       " ('ca', 2),\n",
       " ('shall', 2),\n",
       " ('Should', 1),\n",
       " ('Would', 1),\n",
       " ('ought', 1),\n",
       " ('Could', 1)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counter('MD', news_df['POS_sents'])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 678),\n",
       " ('said', 376),\n",
       " ('are', 338),\n",
       " ('be', 296),\n",
       " ('has', 266),\n",
       " ('have', 220),\n",
       " ('was', 164),\n",
       " ('been', 86),\n",
       " ('do', 72),\n",
       " ('had', 69),\n",
       " (\"'s\", 61),\n",
       " ('were', 55),\n",
       " ('made', 53),\n",
       " ('including', 49),\n",
       " ('s', 47),\n",
       " ('being', 46),\n",
       " ('developing', 45),\n",
       " ('make', 43),\n",
       " ('need', 43),\n",
       " ('take', 42)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counter('VB', news_df['POS_sents'])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the most common verbs are 'is', which could be indicative of passive voice in news, and 'said', which is expected given news reporting of quotes. Our verbs lean more towards the present (are, is) and, interestingly, the future (will). <br>\n",
    "Let's look at the different verbs that are being conjugated in both past and future tenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 64),\n",
       " ('have', 7),\n",
       " ('continue', 5),\n",
       " ('need', 5),\n",
       " ('hold', 4),\n",
       " ('take', 4),\n",
       " ('bring', 4),\n",
       " ('stick', 3),\n",
       " ('reach', 3),\n",
       " ('depend', 3),\n",
       " ('find', 2),\n",
       " ('host', 2),\n",
       " ('remain', 2),\n",
       " ('withdraw', 2),\n",
       " ('start', 2),\n",
       " ('see', 2),\n",
       " ('increase', 2),\n",
       " ('affect', 2),\n",
       " ('change', 2),\n",
       " ('go', 2),\n",
       " ('benefit', 2),\n",
       " ('come', 2),\n",
       " ('leave', 2),\n",
       " ('put', 2),\n",
       " ('try', 2),\n",
       " ('exceed', 2),\n",
       " ('promote', 2),\n",
       " ('live', 1),\n",
       " ('consume', 1),\n",
       " ('advise', 1),\n",
       " ('include', 1),\n",
       " ('become', 1),\n",
       " ('react', 1),\n",
       " ('stay', 1),\n",
       " ('require', 1),\n",
       " ('allocate', 1),\n",
       " ('announce', 1),\n",
       " ('tell', 1),\n",
       " ('invite', 1),\n",
       " ('introduce', 1),\n",
       " ('send', 1),\n",
       " ('speak', 1),\n",
       " ('convene', 1),\n",
       " ('reduce', 1),\n",
       " ('reveal', 1),\n",
       " ('ensure', 1),\n",
       " ('drive', 1),\n",
       " ('spare', 1),\n",
       " ('sustain', 1),\n",
       " ('drop', 1),\n",
       " ('act', 1),\n",
       " ('provide', 1),\n",
       " ('study', 1),\n",
       " ('get', 1),\n",
       " ('occur', 1),\n",
       " ('replace', 1),\n",
       " ('dominate', 1),\n",
       " ('argue', 1),\n",
       " ('necessitate', 1),\n",
       " ('strengthen', 1)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_collocation_counter('VB', news_df['POS_sents'], 'will')[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a tonal mix here, with verbs like 'sustain' and 'benefit' on the positive side, and 'exceed' and 'withdraw' on the negative side, with multiple verbs being more neutral ('require', 'stick'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('been', 25),\n",
       " ('seen', 3),\n",
       " ('reached', 3),\n",
       " ('shown', 3),\n",
       " ('had', 3),\n",
       " ('committed', 3),\n",
       " ('lost', 2),\n",
       " ('gone', 2),\n",
       " ('exceeded', 2),\n",
       " ('left', 2),\n",
       " ('fallen', 2),\n",
       " ('made', 2),\n",
       " ('found', 2),\n",
       " ('depleted', 2),\n",
       " ('failed', 2),\n",
       " ('proposed', 2),\n",
       " ('contributed', 2),\n",
       " ('done', 2),\n",
       " ('witnessed', 2),\n",
       " ('gained', 1),\n",
       " ('mobilised', 1),\n",
       " ('formed', 1),\n",
       " ('set', 1),\n",
       " ('outlived', 1),\n",
       " ('urged', 1),\n",
       " ('used', 1),\n",
       " ('lagged', 1),\n",
       " ('become', 1),\n",
       " ('caused', 1),\n",
       " ('stepped', 1)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_collocation_counter('VB', news_df['POS_sents'], 'have')[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very different set of verbs now, with a stronger attitude. Now verbs such as 'depleted', 'failed', 'reached' and 'lost' tell us the narrative that negative consequences have happened.\n",
    "In conjunction with the verbs used in the future tense, the narrative news seem to be telling is one of a tragic past and an uncertain future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('important', 5),\n",
       " ('necessary', 4),\n",
       " ('more', 4),\n",
       " ('likely', 3),\n",
       " ('critical', 3),\n",
       " ('obvious', 2),\n",
       " ('worth', 2),\n",
       " ('great', 2),\n",
       " ('willing', 2),\n",
       " ('ready', 2),\n",
       " ('real', 2),\n",
       " ('valid', 2),\n",
       " ('unlikely', 2),\n",
       " ('interested', 2),\n",
       " ('strong', 2),\n",
       " ('hard', 1),\n",
       " ('accessible', 1),\n",
       " ('superior', 1),\n",
       " ('vital', 1),\n",
       " ('restorative', 1),\n",
       " ('inconclusive', 1),\n",
       " ('relevant', 1),\n",
       " ('basic', 1),\n",
       " ('uncertain', 1),\n",
       " ('possible', 1),\n",
       " ('intermittent', 1),\n",
       " ('unfamiliar', 1),\n",
       " ('such', 1),\n",
       " ('laughable', 1),\n",
       " ('widespread', 1)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_collocation_counter('JJ', news_df['POS_sents'], 'is')[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjectives we have tell a story of the importance ('important', 'necessary', 'critical', 'vital', 'widespread') of the topic. The adjectives are in general very strong, which is interesting on itself, they are overwhelmingly not about subtlety, which might reflect the psychological state that reporters want to convey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Named-Entity Recognition\n",
    "\n",
    "Named Entity Recognition (NER) is also a classification task, which identifies named objects. Included with Stanford NER are a 4 class model trained on the CoNLL 2003 eng.train, a 7 class model trained on the MUC 6 and MUC 7 training data sets, and a 3 class model trained on both data sets plus some additional data (including ACE 2002 and limited data in-house) on the intersection of those class sets. \n",
    "\n",
    "**3 class**:\tLocation, Person, Organization\n",
    "\n",
    "**4 class**:\tLocation, Person, Organization, Misc\n",
    "\n",
    "**7 class**:\tLocation, Person, Organization, Money, Percent, Date, Time\n",
    "\n",
    "These models each use distributional similarity features, which provide some performance gain at the cost of increasing their size and runtime. Also available are the same models missing those features.\n",
    "\n",
    "(We note that the training data for the 3 class model does not include any material from the CoNLL eng.testa or eng.testb data sets, nor any of the MUC 6 or 7 test or devtest datasets, nor Alan Ritter's Twitter NER data, so all of these would be valid tests of its performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, we tag our first set of exemplary sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classified_sents = stanford.nerTagger.tag_sents(tokenized_text)\n",
    "print(classified_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also run NER over our entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['classified_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['classified_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Find the most common entities (which are, of course, boring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "entityCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if ent in entityCounts:\n",
    "                entityCounts[ent] += 1\n",
    "            else:\n",
    "                entityCounts[ent] = 1\n",
    "sortedEntities = sorted(entityCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedEntities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or those occurring only twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "[x[0] for x in sortedEntities if x[1] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We could also list the most common \"non-objects\". (We note that we're not graphing these because there are so few here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nonObjCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind == 'O':\n",
    "                continue\n",
    "            elif ent in nonObjCounts:\n",
    "                nonObjCounts[ent] += 1\n",
    "            else:\n",
    "                nonObjCounts[ent] = 1\n",
    "sortedNonObj = sorted(nonObjCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedNonObj[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What about the Organizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "OrgCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != 'ORGANIZATION':\n",
    "                continue\n",
    "            elif ent in OrgCounts:\n",
    "                OrgCounts[ent] += 1\n",
    "            else:\n",
    "                OrgCounts[ent] = 1\n",
    "sortedOrgs = sorted(OrgCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedOrgs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These, of course, have much smaller counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform NER on a (modest) subset of your corpus of interest. List all of the different kinds of entities tagged? What does their distribution suggest about the focus of your corpus? For a subset of your corpus, tally at least one type of named entity and calculate the Precision, Recall and F-score for the NER classification just performed (using your own hand-codings as \"ground truth\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['classified_sents'] = news_df['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOCATION': 1363, 'O': 60580, 'ORGANIZATION': 1710, 'PERSON': 1258}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def type_counter(sentences):\n",
    "    dict_counts = {}\n",
    "    for entry in sentences:\n",
    "        for sentence in entry:\n",
    "            for ent, kind in sentence:\n",
    "                if kind in dict_counts:\n",
    "                    dict_counts[kind] += 1\n",
    "                else:\n",
    "                    dict_counts[kind] = 1\n",
    "    return dict_counts\n",
    "type_counter(news_df['classified_sents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have numbers on a similar scale for locations, organizations and people, with other objects on a larger scale. The first one probably reflects the setting up the context of the news articles, which usually include locations and organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', 94),\n",
       " ('Xi', 40),\n",
       " ('Donald', 33),\n",
       " ('Brown', 19),\n",
       " ('Howe', 18),\n",
       " ('Harvey', 16),\n",
       " ('Jinping', 14),\n",
       " ('Obama', 11),\n",
       " ('Merkel', 10),\n",
       " ('Prasad', 10),\n",
       " ('Irma', 10),\n",
       " ('Al', 9),\n",
       " ('Joseph', 9),\n",
       " ('Scott', 9),\n",
       " ('Lee', 8),\n",
       " ('Peter', 8),\n",
       " ('Shehu', 8),\n",
       " ('Glynn', 8),\n",
       " ('Barack', 7),\n",
       " ('Macron', 7),\n",
       " ('Michael', 7),\n",
       " ('Buhari', 7),\n",
       " ('Scaramucci', 7),\n",
       " ('Baker', 6),\n",
       " ('Pruitt', 6),\n",
       " ('Abbott', 6),\n",
       " ('Wang', 6),\n",
       " ('Mutua', 6),\n",
       " ('Boeve', 6),\n",
       " ('Paul', 5)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counter(pos_sentences=news_df['classified_sents'], target_pos='PERSON')[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Earth Day this year, there are reasons to be optimistic about the ability of the United States to lead the fight against climate change and to meet our commitments under the 2015 Paris climate change agreement. Much of that leadership is coming from states, cities, businesses, and consumers. However, it's also coming also from the nonpartisan Citizens' Climate Lobby and increasingly, from leaders of both parties advocating for climate action, and a carbon fee and dividend plan. What is this group, and what is this plan?  The nonprofit Citizens' Climate Lobby (citizensclimatelobby. rg) is a grass-roots advocacy organization with chapters across the United States and around the world. Members — anyone can join — engage local, state, and federal policy makers to build the political will to tackle the challenges of climate change. The Corvallis chapter meets the second Thursday of each month at the North Coop meeting room at 5 p. .  The three parts of the carbon fee and dividend plan are as follows:  First: a gradually increasing fee, or tax, on greenhouse gases at the point where they enter the economy — at the mine, well, refinery, or port. The Citizens Climate Lobby proposes a fee to start at $15 a ton, with a rise of $10 each year, and includes methane and carbon dioxide as greenhouse gases.  Second: money! — distributed to all Americans equally every year on a quarterly basis, by the Social Security Administration. All of the carbon fee/tax money collected would be distributed under both the groups' proposals. A family of four would receive a \"carbon dividend payment\" of about $2,000 in the first year. The payments would grow annually as the carbon fee or tax increased.  Third: \"border carbon adjustments,\" on imports and exports, depending on the carbon pricing policies of countries with which the United States trades. Proceeds from the adjustments would be added to the dividends sent to all Americans.  Leaders working for climate action include the 36 members (18 Republicans and 18 Democrats) of the bipartisan and rapidly growing Climate Solutions Caucus in the House of Representatives, the 17 Republicans who just introduced the Republican Climate Resolution in the House, the 12 Democrats who have introduced bills to price carbon emissions in Congress in recent years, and a new group of Republican elder statesmen — the Climate Leadership Council (clcouncil. rg) — advocating for a carbon fee and dividend as an effective and workable solution for climate change. Among their members are James Baker and George Shultz, both former secretaries of state and of the treasury. The Climate Leadership Council was begun in the recognition that the Republican Party has been in denial of global climate change for too long.  Just after the November elections, 66 percent of voters surveyed by the Yale Program on Climate Change declared their support for a carbon tax with the money used to reduce personal taxes.  We all share our planet's atmosphere. The carbon fee and dividend plan makes economic, social, and environmental sense.  What can you do? Be proactive! Contact your congressional representative: Sens. Merkley (\n"
     ]
    }
   ],
   "source": [
    "print(news_df['text'].iloc[32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the subset of my corpus being the above article, there were:\n",
    "\n",
    "\n",
    "| |Organizations | Location | Person|\n",
    "|--|---|---|---|\n",
    "|TP | 10 | 2 | 3 |\n",
    "|FP | 0 | 2 | 0 |\n",
    "|FN | 1 | 1 | 0 |\n",
    "|Prec | 1 | 0.5 | 1 |\n",
    "|Rec | 0.9 | 0.6 | 1 |\n",
    "|F | 0.95 | 0.57 | 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Parsing\n",
    "\n",
    "Here we will introduce the Stanford Parser by feeding it tokenized text from our initial example sentences. The parser is a dependency parser, but this initial program outputs a simple, self-explanatory phrase-structure representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parses = list(stanford.parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "fourthSentParseTree = list(parses[3]) #iterators so be careful about re-running code, without re-running this block\n",
    "print(fourthSentParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Trees are a common data structure and there are a large number of things to do with them. What we are intetered in is the relationship between different types of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def treeRelation(parsetree, relationType, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retList = []\n",
    "        for subT in parsetree.subtrees():\n",
    "            if subT.label() == relationType:\n",
    "                if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                    retList.append([(subT.label(), ' '.join(subT.leaves()))])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def treeSubRelation(parsetree, relationTypeScope, relationTypeTarget, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retSet = set()\n",
    "        for subT in parsetree.subtrees():\n",
    "            if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                if subT.label() == relationTypeScope:\n",
    "                    for subsub in subT.subtrees():\n",
    "                        if subsub.label()==relationTypeTarget:\n",
    "                            retSet.add(' '.join(subsub.leaves()))\n",
    "    return retSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "treeRelation(fourthSentParseTree, 'NP', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that Florida occurs twice in two different nested noun phrases in the sentence. \n",
    "\n",
    "We can also find all of the verbs within the noun phrase defined by one or more target words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "treeSubRelation(fourthSentParseTree, 'NP', 'VBN', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or if we want to to look at the whole tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fourthSentParseTree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or another sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list(parses[1])[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dependency parsing and graph representations\n",
    "\n",
    "Dependency parsing was developed to robustly capture linguistic dependencies from text. The complex tags associated with these parses are detailed [here]('http://universaldependencies.org/u/overview/syntax.html'). When parsing with the dependency parser, we will work directly from the untokenized text. Note that no *processing* takes place before parsing sentences--we do not remove so-called stop words or anything that plays a syntactic role in the sentence, although anaphora resolution and related normalization may be performed before or after parsing to enhance the value of information extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "depParses = list(stanford.depParser.raw_parse_sents(text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "secondSentDepParseTree = list(depParses[1])[0] #iterators so be careful about re-running code, without re-running this block\n",
    "print(secondSentDepParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a graph and we can convert it to a dot file and use that to visulize it. Try traversing the tree and extracting elements that are nearby one another. We note that unless you have the graphviz successfully installed on your computer (which is not necessary to complete this homework), the following graphviz call will trigger an error. If you are interested in installing graphviz and working on a Mac, consider installing through [homebrew](https://brew.sh), a package manager (i.e., with the command \"brew install graphviz\", once brew is installed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    secondSentGraph = graphviz.Source(secondSentDepParseTree.to_dot())\n",
    "except:\n",
    "    secondSentGraph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "secondSentGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or another sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(depParses[3])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also do a dependency parse on the reddit sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "topPostDepParse = list(stanford.depParser.parse_sents(redditTopScores['sentences'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This takes a few seconds, but now lets look at the parse tree from one of the processed sentences.\n",
    "\n",
    "The sentence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "targetSentence = 7\n",
    "print(' '.join(redditTopScores['sentences'][0][targetSentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Which leads to a very rich dependancy tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(topPostDepParse[targetSentence])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, parse a (modest) subset of your corpus of interest. How deep are the phrase structure and dependency parse trees nested? How does parse depth relate to perceived sentence complexity? What are five things you can extract from these parses for subsequent analysis? (e.g., nouns collocated in a noun phrase; adjectives that modify a noun; etc.) Capture these sets of things for a focal set of words (e.g., \"Bush\", \"Obama\", \"Trump\"). What do they reveal about the roles that these entities are perceived to play in the social world inscribed by your texts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import statistics\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from itertools import chain\n",
    "\n",
    "news_df['text'] = news_df['text'].apply(lambda x: re.sub(r'\\.\\S', r'. ', x))\n",
    "news_df['sentences_untokenized'] = news_df['text'].apply(lambda x: nltk.sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['parse_trees'] = news_df['sentences_untokenized'].apply(lambda x: [list(a) for a in stanford.depParser.raw_parse_sents(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6927662957074725"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121347780>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne9HF1KsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1212f33c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_heights = list(chain(*[[dtree[0].tree().height() for dtree in art_sentences] for art_sentences in news_df['parse_trees']]))\n",
    "\n",
    "statistics.mean(tree_heights)\n",
    "statistics.median(tree_heights)\n",
    "seaborn.distplot(tree_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the average tree height is 5.6 and the median tree height is 6.0. We see the distribution of height levels among the sentences in our sampled news items. Some news items have complexity especially when doing quotes but other than that, the sentences tend to not be as complex as I would expect them to be in, for example, narrative literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things I can extract for subsequent analysis: Verbs acted by someone specific, like Trump, the adjective phrases used to describe climate change, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tree.read(): expected ')' but got 'end-of-string'\n            at index 172.\n                \"...   (. .)))\"\n                              ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-8bfe13b746dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msentlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstanford\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#parses = list(stanford.parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#fourthSentParseTree = list(parses[3]) #iterators so be careful about re-running code, without re-running this block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(fourthSentParseTree)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-8bfe13b746dc>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(sentlist)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msentlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstanford\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#parses = list(stanford.parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#fourthSentParseTree = list(parses[3]) #iterators so be careful about re-running code, without re-running this block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(fourthSentParseTree)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36mparse_sents\u001b[0;34m(self, sentences, verbose)\u001b[0m\n\u001b[1;32m    120\u001b[0m         ]\n\u001b[1;32m    121\u001b[0m         return self._parse_trees_output(self._execute(\n\u001b[0;32m--> 122\u001b[0;31m             cmd, '\\n'.join(' '.join(sentence) for sentence in sentences), verbose))\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36m_parse_trees_output\u001b[0;34m(self, output_)\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mblank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                     \u001b[0mcur_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36m_make_tree\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(cls, s, brackets, read_node, read_leaf, node_pattern, leaf_pattern, remove_empty_top_bracketing)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# check that we got exactly one complete tree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end-of-string'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end-of-string'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_parse_error\u001b[0;34m(cls, s, match, expecting)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n%s\"%s\"\\n%s^'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;31m#////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tree.read(): expected ')' but got 'end-of-string'\n            at index 172.\n                \"...   (. .)))\"\n                              ^"
     ]
    }
   ],
   "source": [
    "news_df['parse_sents'] = news_df['sentences'].apply(lambda sentlist: [list(parsed) for parsed in stanford.parser.parse_sents(sentlist)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tree.read(): expected ')' but got 'end-of-string'\n            at index 172.\n                \"...   (. .)))\"\n                              ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-e45505607b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwithout_problematic_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Staff Writer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnews_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwithout_problematic_one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnews_df2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msentlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstanford\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-e45505607b85>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(sentlist)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwithout_problematic_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Staff Writer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnews_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwithout_problematic_one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnews_df2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msentlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstanford\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36mparse_sents\u001b[0;34m(self, sentences, verbose)\u001b[0m\n\u001b[1;32m    120\u001b[0m         ]\n\u001b[1;32m    121\u001b[0m         return self._parse_trees_output(self._execute(\n\u001b[0;32m--> 122\u001b[0;31m             cmd, '\\n'.join(' '.join(sentence) for sentence in sentences), verbose))\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36m_parse_trees_output\u001b[0;34m(self, output_)\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mblank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                     \u001b[0mcur_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36m_make_tree\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(cls, s, brackets, read_node, read_leaf, node_pattern, leaf_pattern, remove_empty_top_bracketing)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# check that we got exactly one complete tree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end-of-string'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end-of-string'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_parse_error\u001b[0;34m(cls, s, match, expecting)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n%s\"%s\"\\n%s^'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;31m#////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tree.read(): expected ')' but got 'end-of-string'\n            at index 172.\n                \"...   (. .)))\"\n                              ^"
     ]
    }
   ],
   "source": [
    "#list(list(stanford.parser.parse_sents(news_df['sentences'].iloc[32]))[0])\n",
    "without_problematic_one = news_df[~(news_df['author'] == 'Staff Writer')]\n",
    "news_df2 = without_problematic_one\n",
    "news_df2['parse_sents'] = news_df2['sentences'].apply(lambda sentlist: [list(parsed) for parsed in stanford.parser.parse_sents(sentlist)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a problem with some of my news items having an open parenthesis that doesn't close. I didn't know the parser were that sensitive to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California’s hard-charging green governor is shaking things up once again on the world stage. In an affront to President Donald Trump’s controversial decision to pull the United States out of the Paris climate-change agreement, Gov. Jerry Brown will announce a major initiative, inviting nations around the world to join California at a global “climate action” summit meeting in San Francisco.  The video message — to be aired before tens of thousands gathered at the Global Citizen Festival in Hamburg, Germany — comes right in the middle of Trump’s closely watched appearance at the G20 summit.  “It’s up to you and it’s up to me and tens of millions of other people to get it together to roll back the forces of carbonization and join together to combat the existential threat of climate change,” Brown said in prepared remarks releasedby his office. “That is why we’re having the Climate Action Summit in San Francisco, September 2018. President Trump is trying to get out of the Paris Agreement, but he doesn’t speak for the rest of America. We in California and in states all across America believe it’s time to act, it’s time to join together and that’s why at this Climate Action Summit we’re going to get it done.   Brown is making good on his vows to place California, along with its jumbo-sized world-class economy, at the vanguard of governments trying to meet global warming head on. Last December, Brown said the Golden State would put up “its own damn satellites” if Trump cuts funding for projects that gather climate data from space. This evening at the festival, Brown will once again thrown down the gauntlet.  As Trump and other world leaders gather in that city to discuss the Paris climate change accord, California’s CEO will tell the world that Trump does not speak for all Americans when it comes to dealing with environmental concerns.  The New York Times, which obtained an early copy of the governor’s prepared remarks, reported Brown will invite “entrepreneurs, singers, musicians, mathematicians, professors” and others who represent “the whole world” to the San Francisco summit.  In the past two months, Brown has waged a public activist campaign to counter Trump, who declared last month that the U. . would pull out of the 2015 accord. That agreement included pledges by nearly 200 nations to reduce greenhouse gas emissions and help poor countries battle climate change by developing clean sources of energy. Shortly after Trump’s announcement, Brown traveled to China, where he signed an agreement to work together on reducing emissions, warning that “disaster still looms” unless governments around the world take urgent action. On that trip, Brown predicted that Trump’s decision to withdraw from the Paris accord would prove to be only a temporary setback, thanks to firm commitments by China, European countries and individual U. . states to pick up the leadership role vacated by the president.  “President Trump, he’s going off the reservation hopefully for a month, a year, not much longer,” Brown told the Mercury News and East Bay Times before departing for China. “If he stays on his present course, California will just redouble its efforts and the people of the world will have to rise up and take action. And I think in a very paradoxical way, that’s exactly what Trump is stimulating — the very opposite of climate denial is climate activism.   But the governor’s latest action is arguably his most politically aggressive yet, sure to draw criticism as well as praise.  “It’s brazen on several levels,” from “stepping on the president’s trip” to “thinking he speaks for the American people,” said Bill Whalen, a longtime GOP strategist who is now a research fellow at Stanford’s Hoover Institution, The San Francisco summit is not likely to accomplish much, Whalen said, besides gathering people to “collectively thumb their nose at the American president.   “To what end will this conference change anything other than pumping more carbon in the atmosphere as people fly from all over the world to get here?” he asked. “It’s not going to change climate change policy in America, and it’s not going to change Donald Trump’s mind.   According to Brown’s advisers, it will be the first meeting an American state has hosted to support the Paris agreement. Former United Nations climate chief Christiana Figueres, who will introduce Brown tonight, says the global meeting will send a strong message that the president is not speaking on behalf of all Americans, most of whom believe climate change poses real threats to everyone on the planet.  “A summit like that takes on even more importance because,” said Figueres, “it has become even more crucial for the United States to see evidence of the fact that the U. . economy continues to decarbonize.   The governor will speak via video during the final hour of the Global Citizen Festival. The annual event has drawn huge crowds and featured remarks from Canadian Prime Minister Justin Trudeau, Norweigan Prime Minister Erna Solberg and Argentinian President Mauricio Macri, along with performances from Coldplay, Shakira, Pharrell Williams and others.  According to Brown’s office, the September summit, which will take place ahead of the 14th United Nations Framework Convention on Climate Change, will convene representatives from “subnational governments, businesses, investors and civil society … to demonstrate the groundswell of innovative, ambitious climate action from leaders around the world, highlight the economic and environmental transition already underway and spur deeper commitment from all parties, including national governments.  It will be a part of a larger effort around the globe to recruit and lobby governments and municipalities of all sizes to make good on pledges to fight climate change.  Earlier this week, Brown joined the leaders of Baden-Württemberg, Catalonia and South Australia – all members of the Under2 Coalition – to urge the G20 to reaffirm its support for implementation of the Paris Agreement and to recognize the role of sub-national governments, states, regions and cities, in leading and delivering on climate action.  “All over the world, momentum is building to deal seriously with climate change,” Brown said in statement. “Despite rejection in Washington, California is all in. We are fully committed to the Under2 Coalition and the Paris Agreement. \n"
     ]
    }
   ],
   "source": [
    "news_df2=news_df2.iloc[0:15]\n",
    "print(news_df2.text.iloc[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. After significantly decreasing the sample to 14 articles, I've read them all and they don't have any unclosed parenthesis. I'm not sure why the parser is just not working with them. \n",
    "I'll include code that I think would have done one of the analysis but I can't run this at all on my corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing\n",
    "news_df2['parse_sents'] = news_df2['sentences'].apply(lambda sentlist: [list(parsed) for parsed in stanford.parser.parse_sents(sentlist)])\n",
    "\n",
    "# Getting verbs from China\n",
    "chinaVerbs = news_df['parse_trees'].apply(lambda treelist: [treeSubRelation(each_tree, 'VBN', 'NNP', 'China') for each_tree in treelist])\n",
    "\n",
    "# Getting climate change verbs\n",
    "cchangeverbs = news_df['parse_trees'].apply(lambda treelist: [treeSubRelation(each_tree, 'VBN', 'NN', 'climate', 'change') for each_tree in treelist])\n",
    "\n",
    "# Getting adjectives on 'action'\n",
    "actionadjs = cchangeverbs = news_df['parse_trees'].apply(lambda treelist: [treeSubRelation(each_tree, 'JJ', 'NN', 'action') for each_tree in treelist])\n",
    "\n",
    "# Getting adjectives on 'agreement'\n",
    "actionadjs = cchangeverbs = news_df['parse_trees'].apply(lambda treelist: [treeSubRelation(each_tree, 'JJ', 'NN', 'agreement') for each_tree in treelist])\n",
    "\n",
    "# Getting noun phrases by 'Trump'\n",
    "actionadjs = cchangeverbs = news_df['parse_trees'].apply(lambda treelist: [treeRelation(each_tree, 'NP', 'Trump') for each_tree in treelist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "😞😢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Information extraction\n",
    "\n",
    "Information extraction approaches typically (as here, with Stanford's Open IE engine) ride atop the dependency parse of a sentence. They are a pre-coded example of the type analyzed in the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.2 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 18.071 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [19.8 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0098 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /Users/Molo/OneDrive/School/content/content-analysis-2018/7-Information-Extraction/tmpkadhs14e\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ieDF = stanford.openIE(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`openIE()` prints everything stanford core produces and we can see from looking at it that initializing the dependency parser takes most of the time, so calling the function will always take at least 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>elephant</td>\n",
       "      <td>is in</td>\n",
       "      <td>my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant in my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed stimulus efforts in</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent intervie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview with Wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "      <td>is in</td>\n",
       "      <td>recent interview with Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview with Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>recent interview</td>\n",
       "      <td>is with</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certainty                      subject                           verb  \\\n",
       "0         1.0                     elephant                          is in   \n",
       "1         1.0                            I                            saw   \n",
       "2         1.0                            I                            saw   \n",
       "3         1.0              quick brown fox                    jumped over   \n",
       "4         1.0              quick brown fox                    jumped over   \n",
       "5         1.0                    quick fox                    jumped over   \n",
       "6         1.0                          fox                    jumped over   \n",
       "7         1.0                    brown fox                    jumped over   \n",
       "8         1.0                    brown fox                    jumped over   \n",
       "9         1.0                    quick fox                    jumped over   \n",
       "10        1.0                          fox                    jumped over   \n",
       "11        1.0            Christine Lagarde                      discussed   \n",
       "12        1.0            Christine Lagarde                      discussed   \n",
       "13        1.0            Christine Lagarde                      discussed   \n",
       "14        1.0            Christine Lagarde  discussed stimulus efforts in   \n",
       "15        1.0            Christine Lagarde                      discussed   \n",
       "16        1.0            Christine Lagarde                      discussed   \n",
       "17        1.0            Christine Lagarde                      discussed   \n",
       "18        1.0  short-term stimulus efforts                          is in   \n",
       "19        1.0            Christine Lagarde                      discussed   \n",
       "20        1.0            Christine Lagarde                      discussed   \n",
       "21        1.0            Christine Lagarde                      discussed   \n",
       "22        1.0            Christine Lagarde                      discussed   \n",
       "23        1.0             recent interview                        is with   \n",
       "24        1.0                       Martin                            was   \n",
       "25        1.0      Trayvon Benjamin Martin      was African American from   \n",
       "26        1.0      Trayvon Benjamin Martin              was American from   \n",
       "27        1.0      Trayvon Benjamin Martin                            was   \n",
       "28        1.0      Trayvon Benjamin Martin                            was   \n",
       "\n",
       "                                               object  \n",
       "0                                          my pajamas  \n",
       "1                              elephant in my pajamas  \n",
       "2                                            elephant  \n",
       "3                                            lazy dog  \n",
       "4                                                 dog  \n",
       "5                                                 dog  \n",
       "6                                                 dog  \n",
       "7                                            lazy dog  \n",
       "8                                                 dog  \n",
       "9                                            lazy dog  \n",
       "10                                           lazy dog  \n",
       "11  short-term stimulus efforts in interview with ...  \n",
       "12                      stimulus efforts in interview  \n",
       "13               stimulus efforts in recent interview  \n",
       "14                                             France  \n",
       "15  short-term stimulus efforts in recent intervie...  \n",
       "16  stimulus efforts in recent interview with Wall...  \n",
       "17    short-term stimulus efforts in recent interview  \n",
       "18          recent interview with Wall Street Journal  \n",
       "19  stimulus efforts in interview with Wall Street...  \n",
       "20                                   stimulus efforts  \n",
       "21                        short-term stimulus efforts  \n",
       "22           short-term stimulus efforts in interview  \n",
       "23                                Wall Street Journal  \n",
       "24                                            African  \n",
       "25                                            Florida  \n",
       "26                                            Florida  \n",
       "27                                           American  \n",
       "28                                   African American  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "No buffalos (because there were no verbs), but the rest is somewhat promising. Note, however, that it abandoned the key theme of the sentence about the tragic Trayvon Martin death (\"fatally shot\"), likely because it was buried so deeply within the complex phrase structure. This is obviously a challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">How would you extract relevant information about the Trayvon Martin sentence directly from the dependency parse (above)? Code an example here. (For instance, what compound nouns show up with what verb phrases within the sentence?) How could these approaches inform your research project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above parsing only leaves 5 items about Trayvon Martin. One of them is false, as he was not African. However, if we had a large corpus of similar news items, we could compute the number of times 'African American' is coupled with the verb 'was', compared to other groups and their verb tenses, to figure out if certain groups are being described as deceased or to uncover bias in active verbs.\n",
    "An example of that code would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "was    1\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['object'].apply(lambda x: 'African American' in x)]['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These approaches are useful in terms of determining actors and objects. Grabbing inspiration from the orienting read of this week, I could look at what specific actors (countries, for example) are 'doing' in the articles of climate change and then attempt to find patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And we can also look for subject, object, target triples in one of the reddit stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ieDF = stanford.openIE(redditTopScores['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That's almost 200 triples in only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(redditTopScores['sentences'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "sentences and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sum([len(s) for s in redditTopScores['sentences'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lets find at the most common subject in this story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I is followed by various male pronouns and compound nouns (e.g., \"old man\"). 'I' occures most often with the following verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "and the following objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also run the corenlp server. When you run this server (with the command below), you can click on the browswer link provided to experiment with it. Note that when we run the server, executing the command below, it interrupts the current jupyter process and you will not be able to run code here again (processes will \"hang\" and never finish) until you interrup the process by clicking \"Kernel\" and then \"Interrupt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stanford.startCoreServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform open information extraction on a modest subset of texts relevant to your final project. Analyze the relative attachment of several subjects relative to verbs and objects and visa versa. Describe how you would select among these statements to create a database of high-value statements for your project and then do it by extracting relevant statements into a pandas dataframe."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
